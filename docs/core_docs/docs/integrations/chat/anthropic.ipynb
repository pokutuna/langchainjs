{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Anthropic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatAnthropic\n",
    "\n",
    "[Anthropic](https://www.anthropic.com/) is an AI safety and research company. They are the creator of Claude.\n",
    "\n",
    "This will help you getting started with Anthropic [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatAnthropic` features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/chat/anthropic/) | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
    "| [ChatAnthropic](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html) | [`@langchain/anthropic`](https://www.npmjs.com/package/@langchain/anthropic) | ❌ | ✅ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/anthropic?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/anthropic?style=flat-square&label=%20&) |\n",
    "\n",
    "### Model features\n",
    "\n",
    "See the links in the table headers below for guides on how to use specific features.\n",
    "\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ❌ | ✅ | ❌ | ❌ | ✅ | ✅ | ❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "You'll need to sign up and obtain an [Anthropic API key](https://www.anthropic.com/), and install the `@langchain/anthropic` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Anthropic's website](https://www.anthropic.com/) to sign up to Anthropic and generate an API key. Once you've done this set the `ANTHROPIC_API_KEY` environment variable:\n",
    "\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n",
    "\n",
    "```bash\n",
    "# export LANGCHAIN_TRACING_V2=\"true\"\n",
    "# export LANGCHAIN_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "### Installation\n",
    "\n",
    "The LangChain `ChatAnthropic` integration lives in the `@langchain/anthropic` package:\n",
    "\n",
    "```{=mdx}\n",
    "\n",
    "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
    "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
    "\n",
    "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
    "\n",
    "<Npm2Yarn>\n",
    "  @langchain/anthropic\n",
    "</Npm2Yarn>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\" \n",
    "\n",
    "const llm = new ChatAnthropic({\n",
    "    model: \"claude-3-haiku-20240307\",\n",
    "    temperature: 0,\n",
    "    maxTokens: undefined,\n",
    "    maxRetries: 2,\n",
    "    // other params...\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_013WBXXiggy6gMbAUY6NpsuU\",\n",
      "  \"content\": \"Voici la traduction en français :\\n\\nJ'adore la programmation.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_013WBXXiggy6gMbAUY6NpsuU\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 29,\n",
      "      \"output_tokens\": 20\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_013WBXXiggy6gMbAUY6NpsuU\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 29,\n",
      "      \"output_tokens\": 20\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 29,\n",
      "    \"output_tokens\": 20,\n",
      "    \"total_tokens\": 49\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const aiMsg = await llm.invoke([\n",
    "    [\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ],\n",
    "    [\"human\", \"I love programming.\"],\n",
    "])\n",
    "aiMsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici la traduction en français :\n",
      "\n",
      "J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "console.log(aiMsg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01Ca52fpd1mcGRhH4spzAWr4\",\n",
      "  \"content\": \"Ich liebe das Programmieren.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01Ca52fpd1mcGRhH4spzAWr4\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 23,\n",
      "      \"output_tokens\": 11\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01Ca52fpd1mcGRhH4spzAWr4\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 23,\n",
      "      \"output_tokens\": 11\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 23,\n",
      "    \"output_tokens\": 11,\n",
      "    \"total_tokens\": 34\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\"\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages(\n",
    "    [\n",
    "        [\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ],\n",
    "        [\"human\", \"{input}\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "const chain = prompt.pipe(llm);\n",
    "await chain.invoke(\n",
    "    {\n",
    "        input_language: \"English\",\n",
    "        output_language: \"German\",\n",
    "        input: \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac39db",
   "metadata": {},
   "source": [
    "## Content blocks\n",
    "\n",
    "One key difference to note between Anthropic models and most others is that the contents of a single Anthropic AI message can either be a single string or a **list of content blocks**. For example when an Anthropic model [calls a tool](/docs/how_to/tool_calling), the tool invocation is part of the message content (as well as being exposed in the standardized `AIMessage.tool_calls` field):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5994de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01DZGs9DyuashaYxJ4WWpWUP\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"Here is the calculation for 2 + 2:\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_use\",\n",
      "      \"id\": \"toolu_01SQXBamkBr6K6NdHE7GWwF8\",\n",
      "      \"name\": \"calculator\",\n",
      "      \"input\": {\n",
      "        \"number1\": 2,\n",
      "        \"number2\": 2,\n",
      "        \"operation\": \"add\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01DZGs9DyuashaYxJ4WWpWUP\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"tool_use\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 449,\n",
      "      \"output_tokens\": 100\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01DZGs9DyuashaYxJ4WWpWUP\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"tool_use\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 449,\n",
      "      \"output_tokens\": 100\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"name\": \"calculator\",\n",
      "      \"args\": {\n",
      "        \"number1\": 2,\n",
      "        \"number2\": 2,\n",
      "        \"operation\": \"add\"\n",
      "      },\n",
      "      \"id\": \"toolu_01SQXBamkBr6K6NdHE7GWwF8\",\n",
      "      \"type\": \"tool_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 449,\n",
      "    \"output_tokens\": 100,\n",
      "    \"total_tokens\": 549\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "const calculatorSchema = z.object({\n",
    "  operation: z\n",
    "    .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])\n",
    "    .describe(\"The type of operation to execute.\"),\n",
    "  number1: z.number().describe(\"The first number to operate on.\"),\n",
    "  number2: z.number().describe(\"The second number to operate on.\"),\n",
    "});\n",
    "\n",
    "const calculatorTool = {\n",
    "  name: \"calculator\",\n",
    "  description: \"A simple calculator tool\",\n",
    "  input_schema: zodToJsonSchema(calculatorSchema),\n",
    "};\n",
    "\n",
    "const toolCallingLlm = new ChatAnthropic({\n",
    "  model: \"claude-3-haiku-20240307\",\n",
    "}).bindTools([calculatorTool]);\n",
    "\n",
    "const toolPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"You are a helpful assistant who always needs to use a calculator.\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "// Chain your prompt and model together\n",
    "const toolCallChain = toolPrompt.pipe(toolCallingLlm);\n",
    "\n",
    "await toolCallChain.invoke({\n",
    "  input: \"What is 2 + 2?\",\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452d4b6",
   "metadata": {},
   "source": [
    "## Custom headers\n",
    "\n",
    "You can pass custom headers in your requests like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41943f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_019z4nWpShzsrbSHTWXWQh6z\",\n",
      "  \"content\": \"The sky appears blue due to a phenomenon called Rayleigh scattering. Here's a brief explanation:\\n\\n1) Sunlight is made up of different wavelengths of visible light, including all the colors of the rainbow.\\n\\n2) As sunlight passes through the atmosphere, the gases (mostly nitrogen and oxygen) cause the shorter wavelengths of light, such as violet and blue, to be scattered more easily than the longer wavelengths like red and orange.\\n\\n3) This scattering of the shorter blue wavelengths occurs in all directions by the gas molecules in the atmosphere.\\n\\n4) Our eyes are more sensitive to the scattered blue light than the scattered violet light, so we perceive the sky as having a blue color.\\n\\n5) The scattering is more pronounced for light traveling over longer distances through the atmosphere. This is why the sky appears even darker blue when looking towards the horizon.\\n\\nSo in essence, the selective scattering of the shorter blue wavelengths of sunlight by the gases in the atmosphere is what causes the sky to appear blue to our eyes during the daytime.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_019z4nWpShzsrbSHTWXWQh6z\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 13,\n",
      "      \"output_tokens\": 236\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_019z4nWpShzsrbSHTWXWQh6z\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 13,\n",
      "      \"output_tokens\": 236\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 13,\n",
      "    \"output_tokens\": 236,\n",
      "    \"total_tokens\": 249\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const llmWithCustomHeaders = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "  maxTokens: 1024,\n",
    "  clientOptions: {\n",
    "    defaultHeaders: {\n",
    "      \"X-Api-Key\": process.env.ANTHROPIC_API_KEY,\n",
    "    },\n",
    "  },\n",
    "});\n",
    "\n",
    "await llmWithCustomHeaders.invoke(\"Why is the sky blue?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatAnthropic features and configurations head to the API reference: https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
